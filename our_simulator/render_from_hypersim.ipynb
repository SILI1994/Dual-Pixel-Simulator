{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8c49812-8a5d-4c08-9c5b-b6752f7df930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from model_our_sim import DPSimulator\n",
    "import numpy as np\n",
    "from dataset import HypersimDataset\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9076239-59b1-402f-b78c-f7a6f4d1b0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def save_h5py_file(name, my_dict):\n",
    "    h = h5py.File(name, 'w')\n",
    "    for k, v in my_dict.items():\n",
    "        h.create_dataset(k, data=np.array([v]).squeeze())\n",
    "    h.close()\n",
    "\n",
    "\n",
    "\n",
    "def norm_dep(dep):\n",
    "    all_new_dep = torch.zeros_like(dep)\n",
    "    for i, x in enumerate(dep):\n",
    "        curr_mask = x != 0\n",
    "        x[x == 0] = x.max()\n",
    "        new_dep = (x - x.min()) / (x.max() - x.min())\n",
    "        new_dep[curr_mask == 0] = -1\n",
    "        all_new_dep[i] = new_dep\n",
    "    return all_new_dep\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "314a0701-1c2c-4063-b547-6f0cab784294",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generate_dp_from_rgbd(args, hypersim_partition):\n",
    "    ## dataloader\n",
    "    test_set = HypersimDataset(os.path.join(args.data_dir, hypersim_partition))\n",
    "    test_loader = DataLoader(test_set, batch_size=1, shuffle=False, num_workers=args.n_worker, drop_last=False)\n",
    "    print('validation size: {}'.format(test_set.__len__()))\n",
    "\n",
    "    ## initialization\n",
    "    save_dir = os.path.join(args.generated_dp_dir, hypersim_partition)\n",
    "    Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "    model = DPSimulator(k_size=5)\n",
    "    model.load_state_dict(torch.load(args.cp_dir, map_location='cpu'))\n",
    "    model = model.to(args.device)\n",
    "    print('init done')\n",
    "\n",
    "    ## test\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(tqdm(test_loader)):\n",
    "            sharp, dep, coc = data['sharp'].to(args.device), data['dep'].to(args.device), data['coc'].to(args.device)\n",
    "            normalized_dep = norm_dep(dep)\n",
    "            \n",
    "            with torch.cuda.amp.autocast():\n",
    "                pred_l, pred_r, _, _ = model(sharp, normalized_dep, coc)\n",
    "            pred_l, pred_r = torch.clip(pred_l, 0, 1), torch.clip(pred_r, 0, 1)\n",
    "\n",
    "            ## save h5 file\n",
    "            my_dict = {'dp_l': pred_l.detach().cpu().numpy(), 'dp_r': pred_r.detach().cpu().numpy(), 'sharp': data['sharp'].numpy(),\n",
    "                       'dep': data['dep'].numpy(), 'coc': data['coc'].numpy(), 'normal': data['normal'].numpy(),\n",
    "                       'focus_dis': data['focus_dis'].numpy(), 'thin_lens_focal_len_in_mm': data['thin_lens_focal_len_in_mm'].numpy(), 'f_number': data['f_number'].numpy(),\n",
    "                       'M': data['M'].numpy(), 'pixel_size': data['pixel_size'].numpy(), 'af_pt': data['af_pt'].numpy()}\n",
    "            save_h5py_file(os.path.join(save_dir, '{}.h5'.format(data['curr_name'][0])), my_dict)\n",
    "            \n",
    "\n",
    "    print('test finished')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787811da-16d7-422d-85e8-4e14a140d5cd",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--device', type=str, default='cuda:5', help='cuda device')\n",
    "    parser.add_argument('--seed', type=int, default=0, help='random seed')\n",
    "    parser.add_argument('--n_worker', type=int, default=8, help='numer of workers')\n",
    "    parser.add_argument('--cp_dir', type=str, default='./checkpoints/DP_simulator_flip_max_val_ssim.cp', help='checkpoint directory')\n",
    "    parser.add_argument('--data_dir', type=str, default='/dataset/workspace2022/li/selected_hypersim', help='data directory')\n",
    "    parser.add_argument('--generated_dp_dir', type=str, default='/dataset/workspace2022/li/compact_generated_dp_from_rgbd_flip', help='data directory')\n",
    "    _args = parser.parse_args(args=[])\n",
    "\n",
    "    # fix seed\n",
    "    np.random.seed(_args.seed)\n",
    "    torch.manual_seed(_args.seed)\n",
    "    random.seed(_args.seed)\n",
    "    if _args.device != 'cpu':\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    # train\n",
    "    \n",
    "    for x in ['partition_0', 'partition_1', 'partition_2', 'partition_3', 'partition_4']:\n",
    "        generate_dp_from_rgbd(_args, x)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}